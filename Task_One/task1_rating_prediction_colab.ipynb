{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pandas requests scikit-learn matplotlib seaborn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import requests\n",
                "import json\n",
                "import time\n",
                "import random\n",
                "from sklearn.metrics import accuracy_score\n",
                "import io\n",
                "import os\n",
                "from google.colab import files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "uploaded = files.upload()\n",
                "\n",
                "filename = \"yelp.csv\"\n",
                "if filename not in uploaded:\n",
                "    if len(uploaded) > 0:\n",
                "        filename = list(uploaded.keys())[0]\n",
                "        print(f\"Using uploaded file: {filename}\")\n",
                "    else:\n",
                "        print(\"No file uploaded. Please rerun this cell and upload 'yelp.csv'.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "API_KEY = \"k_b77bff20013e.3KoZgR-_aVbzchPJeWRhLcl5klaSbDKaMfackYjEjEv64QAoLPO9cw\"\n",
                "API_URL = \"https://platform.qubrid.com/api/v1/qubridai/chat/completions\"\n",
                "MODEL_NAME = \"openai/gpt-oss-120b\"\n",
                "\n",
                "NUM_SAMPLES = 200\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    if filename in uploaded:\n",
                "        df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
                "    elif os.path.exists(filename):\n",
                "        df = pd.read_csv(filename)\n",
                "    else:\n",
                "        raise FileNotFoundError(\"Dataset not found.\")\n",
                "\n",
                "    print(f\"Dataset loaded. Total rows: {len(df)}\")\n",
                "    \n",
                "    if 'stars' in df.columns:\n",
                "        sample_df = df.groupby('stars', group_keys=False).apply(lambda x: x.sample(min(len(x), NUM_SAMPLES // 5), random_state=SEED))\n",
                "        if len(sample_df) < NUM_SAMPLES:\n",
                "            remaining_n = NUM_SAMPLES - len(sample_df)\n",
                "            remaining_df = df.drop(sample_df.index).sample(n=remaining_n, random_state=SEED)\n",
                "            sample_df = pd.concat([sample_df, remaining_df])\n",
                "    else:\n",
                "        sample_df = df.sample(n=NUM_SAMPLES, random_state=SEED)\n",
                "        \n",
                "    sample_df = sample_df.reset_index(drop=True)\n",
                "    print(f\"Sampled {len(sample_df)} reviews.\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Error loading data: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Define Prompts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_zero_shot_prompt(review_text):\n",
                "    return f\"\"\"\n",
                "You are a helpful assistant that analyzes Yelp reviews.\n",
                "Classify the following review into a star rating (1 to 5).\n",
                "Return the result in strictly valid JSON format with keys: \"predicted_stars\" (integer) and \"explanation\" (string).\n",
                "Do not output any markdown formatting or extra text, just the specific JSON.\n",
                "\n",
                "Review: \"{review_text}\"\n",
                "\"\"\"\n",
                "\n",
                "def get_few_shot_prompt(review_text):\n",
                "    return f\"\"\"\n",
                "You are a helpful assistant that analyzes Yelp reviews.\n",
                "Classify the following review into a star rating (1 to 5).\n",
                "Return the result in strictly valid JSON format with keys: \"predicted_stars\" (integer) and \"explanation\" (string).\n",
                "Do not output any markdown formatting or extra text, just the specific JSON.\n",
                "\n",
                "Examples:\n",
                "Review: \"The food was terrible and the service was rude.\"\n",
                "JSON: {{\"predicted_stars\": 1, \"explanation\": \"Negative sentiment regarding both food and service.\"}}\n",
                "\n",
                "Review: \"It was okay, nothing special but not bad.\"\n",
                "JSON: {{\"predicted_stars\": 3, \"explanation\": \"Neutral sentiment, average experience.\"}}\n",
                "\n",
                "Review: \"Absolutely amazing! Best pizza I've ever had.\"\n",
                "JSON: {{\"predicted_stars\": 5, \"explanation\": \"Highly positive sentiment, strong praise.\"}}\n",
                "\n",
                "Review: \"{review_text}\"\n",
                "\"\"\"\n",
                "\n",
                "def get_cot_prompt(review_text):\n",
                "    return f\"\"\"\n",
                "You are a helpful assistant that analyzes Yelp reviews.\n",
                "Classify the following review into a star rating (1 to 5).\n",
                "First, think step-by-step about the sentiment expressed in the review regarding different aspects like food, service, and ambiance.\n",
                "Then, determine the final rating.\n",
                "Return the result in strictly valid JSON format with keys: \"predicted_stars\" (integer) and \"explanation\" (string).\n",
                "Do not output any markdown formatting or extra text, just the specific JSON.\n",
                "\n",
                "Review: \"{review_text}\"\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def call_api(prompt, model=MODEL_NAME):\n",
                "    headers = {\n",
                "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
                "        \"Content-Type\": \"application/json\"\n",
                "    }\n",
                "    data = {\n",
                "        \"model\": model,\n",
                "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
                "        \"temperature\": 0.0,\n",
                "        \"max_tokens\": 1024,\n",
                "        \"stream\": False\n",
                "    }\n",
                "    \n",
                "    retries = 3\n",
                "    for i in range(retries):\n",
                "        try:\n",
                "            response = requests.post(API_URL, headers=headers, json=data, timeout=30)\n",
                "            if response.status_code == 200:\n",
                "                return response.json()\n",
                "            else:\n",
                "                time.sleep(2)\n",
                "        except Exception as e:\n",
                "            time.sleep(2)\n",
                "    return None\n",
                "\n",
                "def parse_response(api_response):\n",
                "    if not api_response:\n",
                "        return None, False\n",
                "    try:\n",
                "        content = api_response.get('choices', [{}])[0].get('message', {}).get('content')\n",
                "        if not content:\n",
                "            content = api_response.get('content')\n",
                "            \n",
                "        if not content: return None, False\n",
                "\n",
                "        content = content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
                "        data = json.loads(content)\n",
                "        return data, True\n",
                "    except:\n",
                "        return None, False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "prompts_map = {\n",
                "    \"Zero-shot\": get_zero_shot_prompt,\n",
                "    \"Few-shot\": get_few_shot_prompt,\n",
                "    \"Chain-of-Thought\": get_cot_prompt\n",
                "}\n",
                "metrics = {strategy: {\"correct\": 0, \"valid_json\": 0, \"total\": 0} for strategy in prompts_map}\n",
                "\n",
                "print(\"Starting evaluation...\")\n",
                "for index, row in sample_df.iterrows():\n",
                "    review_text = row['text']\n",
                "    actual_stars = row['stars']\n",
                "    \n",
                "    row_result = {\n",
                "        \"review_id\": row.get('review_id', index),\n",
                "        \"text\": review_text,\n",
                "        \"actual_stars\": actual_stars\n",
                "    }\n",
                "\n",
                "    for strategy_name, prompt_func in prompts_map.items():\n",
                "        prompt = prompt_func(review_text)\n",
                "        response = call_api(prompt)\n",
                "        data, is_valid = parse_response(response)\n",
                "        \n",
                "        metrics[strategy_name][\"total\"] += 1\n",
                "        row_result[f\"{strategy_name}_valid\"] = is_valid\n",
                "        \n",
                "        if is_valid:\n",
                "            metrics[strategy_name][\"valid_json\"] += 1\n",
                "            p_stars = data.get(\"predicted_stars\")\n",
                "            row_result[f\"{strategy_name}_predicted\"] = p_stars\n",
                "            row_result[f\"{strategy_name}_explanation\"] = data.get(\"explanation\")\n",
                "            \n",
                "            if p_stars == actual_stars:\n",
                "                metrics[strategy_name][\"correct\"] += 1\n",
                "        else:\n",
                "            row_result[f\"{strategy_name}_predicted\"] = None\n",
                "            row_result[f\"{strategy_name}_explanation\"] = \"JSON Parsing Failed\"\n",
                "            \n",
                "        time.sleep(1)\n",
                "    \n",
                "    results.append(row_result)\n",
                "    if (index + 1) % 10 == 0:\n",
                "        print(f\"Processed {index + 1}/{len(sample_df)} reviews\")\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "print(\"Evaluation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Strategy | Accuracy | JSON Validity Rate\")\n",
                "print(\"--- | --- | ---\")\n",
                "for strategy, m in metrics.items():\n",
                "    accuracy = (m[\"correct\"] / m[\"valid_json\"]) * 100 if m[\"valid_json\"] > 0 else 0\n",
                "    validity = (m[\"valid_json\"] / m[\"total\"]) * 100 if m[\"total\"] > 0 else 0\n",
                "    print(f\"{strategy} | {accuracy:.2f}% | {validity:.2f}%\")\n",
                "\n",
                "results_df.to_csv(\"task1_results.csv\", index=False)\n",
                "files.download(\"task1_results.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
